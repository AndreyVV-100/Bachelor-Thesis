\section{Обзор существующих компиляторов нейронных сетей}
\label{sec:Chapter4} \index{Chapter4}

\subsection{Инфраструктуры и стандарты}

Для удобного проектирования, обучения и запуска нейронных сетей создаются
фреймворки (т.~е. библиотеки), поддерживающие большое количество операций
нейросетей и содержащие некоторые заранее натренированные модели и открытые
датасеты (наборы данных), использованные для их обучения. Наиболее популярными
из таких являются \textit{PyTorch} и \textit{TensorFlow}. Обучение и исполнение
моделей в этих фреймворках возможно как на CPU, так и на GPU.

Очевидно, что PyTorch и TensorFlow являются не единственными в своём роде.
По этой причине добавление возможностей исполнения на специализированном
процессоре в каждый фреймворк является нерациональным. Для унификации работы
с фреймворками, создаются стандарты, такие как \textit{ONNX}, \textit{TOSA}
или \textit{StableHLO}. Они создают единую точку входа для специализированных
компиляторов: сначала модель из любого фреймворка конвертируется в модель на
языке стандарта, и именно эту модель принимает на вход компилятор для создания
архитектурно-специфичного кода. Среди таких компиляторов можно выделить
\textit{XLA}, \textit{MindSpore}, \textit{ONNX runtime}. Но все они также
нацелены на исполнение на самых распростаннённых архитектурах: x86-64 (в т.~ч.
с векторизацией при помощи AVX), ARM, GPU (в т.~ч. с использованием технологий
CUDA от Nvidia и ROCm от AMD). Их использование в качестве основы для создания
компилятора для архитектуры DaVinci означало бы написание полного цикла
компиляции из стандарта до ассемблерных инструкцию практически <<с нуля>> и
не давало бы никаких преимуществ. 

\subsection{Оптимизации и полиэдральная компиляция}

Как было упомянуто ранее, одними из основных операций в нейронных сетях
являются умножения матриц и свёртки. Эти операции представляют из себя большое
количество простых и однотипных арифметических операций (сложения и умножения).
По этой причине их можно оптимизировать средствами векторизации и
переупорядочивания обхода циклов. Для этих целей была создана математическая
модель, основанная на алгебраическом представлении программ и их
преобразований, --- полиэдральная модель. В них цикл является полиэдром,
т.~е. многомерным многогранником в аффином пространстве. Аффинные преобразования
этого пространства соответствуют преобразованиям цикла, изменениям порядка
обхода элементов.

Рассмотрим некоторые проекты, использующие этот подход, а именно \textit{TVM},
\textit{Halide} и \textit{Polly}. Polly является частью проекта LLVM и
преобразует LLVM IR для генерации оптимального кода. Его использование привело
бы к необходимости добавления новых инструкций в LLVM IR и не давало бы
достаточных уровней абстракции. Инфраструктуры TVM и Halide позволяют
создавать новые операции, но требуют, чтобы для них был задан способ исполнения.
Такой подход является неудобным, т.~к. это означает, что после преобразований
код должен быть транслирован в ассемблерные инструкции по неким сложным
шаблонам. Более того, в Halide это исполнение задаётся исключительно скалярном
виде. К сожалению, единственный существующий компилятор для Ascend,
преобразующий ONNX модели, --- \textit{Automatic kernel generator (AKG)},
являющийся частью MindSpore, пошёл по этому пути и использует Halide в качестве
инфраструктуры.

\subsection{Итог}

Существует большое количество различных компиляторов для нейронных сетей. Они
используют разлиные подходы для генерации кода, но во многом повторяют друг
друга. По этой причиной одно из крупнейших сообществ --- LLVM --- решило
создать переиспользуемую инфраструктуру MLIR, собирающую в себя лучшее из
различных подходов и техник, в т.~ч. и полиэдральной компиляции. На данный
момент проект активно развивается и является самой современной крупной
инфраструктурой.

\newpage
